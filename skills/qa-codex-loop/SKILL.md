---
name: qa-codex-loop
description: "Execute a QA JSON plan deterministically with explicit tool choice (codex or claude-code), capture per-test outcomes, and emit machine-readable PASS/FAIL artifacts."
user-invocable: true
---

# QA Codex Loop

Execute `test-plan-*.json` artifacts as deterministic QA gates with explicit model/tool choice.

---

## Baseline Reuse Analysis (from `ralph.sh`)

Reusable executor patterns from `ralph.sh`:

1. Argument parsing and strict tool validation (`codex`/`claude` style switch)
2. Predictable logs directory and per-iteration artifact naming
3. Deterministic retry/status classification functions
4. Structured summaries persisted under `logs/`
5. Machine-oriented completion signaling and non-zero exits on failure

These are reused for QA execution by keeping strict input validation, deterministic output locations, and explicit PASS/FAIL status artifacts.

---

## Gap Analysis: `ralph.sh` vs QA Execution Needs

`ralph.sh` is story-loop oriented, but QA execution requires test-loop semantics.

Missing behaviors in `ralph.sh` for QA:

1. JSON test plan ingestion (`qaPlanSchemaVersion`, `tests[]`, per-test metadata)
2. Deterministic per-test execution order (`TC-001`, `TC-002`, ...)
3. Per-test result capture with test-scoped artifacts
4. Aggregate QA gate summary (`total/passed/failed`) independent of git commit detection
5. Machine-readable QA gate output (`status.txt` with exact `PASS`/`FAIL`)

`qa-codex-loop` closes these gaps by using `qa-codex-loop.sh` as a focused executor entrypoint.

---

## The Job

1. Accept one JSON plan path generated by `qa-plan-json`
2. Accept explicit tool choice for the run: `codex` or `claude-code`
3. Execute all tests in deterministic `TC-###` order
4. Persist per-test artifacts and consolidated run summary
5. Emit machine-readable gate status (`PASS`/`FAIL`)

---

## Input Contract

Required inputs:

- `--plan <path>`: readable `test-plan-*.json` file
- `--tool codex|claude-code`: explicit runtime tool

Optional input:

- `--logs-dir <path>`: defaults to `logs/qa-loop`

Schema expectations:

- `qaPlanSchemaVersion` must be `1.0.0`
- `tests[]` must be non-empty
- each test should include deterministic `id`, steps, commands/manual marker, pass criteria, and evidence

If validation fails, stop immediately with actionable error output.

---

## Entrypoint Script

Use the executor script at repo root:

```bash
./qa-codex-loop.sh --plan tasks/test-plan-foo.json --tool codex
```

Claude Code variant:

```bash
./qa-codex-loop.sh --plan tasks/test-plan-foo.json --tool claude-code
```

The script will:

1. Validate input arguments and schema version
2. Create run folder: `logs/qa-loop/<run-id>/`
3. Execute tests in sorted ID order
4. Store per-test artifacts in `logs/qa-loop/<run-id>/tests/<test-id>/`
5. Write `outcomes.jsonl`, `summary.json`, and `status.txt`

---

## Deterministic Execution Rules

1. Sort test cases by numeric ID from `TC-###`
2. Run each test exactly once per pass (no remediation loop here)
3. A test is `PASS` only when tool exit code is zero and output contains `<status>PASS</status>`
4. Any other condition is `FAIL`
5. Final gate status is `PASS` only when all tests pass

---

## Required Artifacts

Per run (`logs/qa-loop/<run-id>/`):

- `plan.json` - copied input plan snapshot
- `run.env` - run metadata (tool, timestamps, plan path)
- `outcomes.jsonl` - one JSON record per test
- `summary.json` - aggregate totals and final status
- `status.txt` - exact string `PASS` or `FAIL`

Per test (`logs/qa-loop/<run-id>/tests/<test-id>/`):

- `prompt.md` - exact test execution instructions sent to tool
- `agent-output.txt` - tool output
- `stderr.log` - stderr stream
- `result.json` - normalized outcome metadata
- `status.txt` - test-level status

---

## Machine-Readable Status Contract

- `status.txt` content is the canonical gate status:
  - `PASS` when all tests passed
  - `FAIL` when one or more tests failed
- script exit code:
  - `0` when `PASS`
  - `1` when `FAIL` or validation error

---

## Handoff

Standard QA pipeline handoff:

1. `qa-plan-generator` emits `test-plan-*.md`
2. `qa-plan-json` emits `test-plan-*.json`
3. `qa-codex-loop` executes JSON plan and emits gate artifacts

---

## Checklist

Before returning execution result:

- [ ] Reviewed and documented `ralph.sh` baseline reuse
- [ ] Documented gap analysis for JSON-plan QA needs
- [ ] Tool choice is explicit (`codex` or `claude-code`)
- [ ] Tests executed in deterministic order
- [ ] Per-test outcomes and aggregate summary are written
- [ ] Machine-readable `PASS`/`FAIL` status emitted
